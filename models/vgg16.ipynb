{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 10350,
     "status": "ok",
     "timestamp": 1737903769712,
     "user": {
      "displayName": "Jithin S John",
      "userId": "11096614169170253604"
     },
     "user_tz": -330
    },
    "id": "cpHTw8gRIG8S"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# Define the paths to the subdirectories\n",
    "\n",
    "car_dir = '/content/drive/MyDrive/Colab Notebooks/dataset/car/'\n",
    "bike_dir = '/content/drive/MyDrive/Colab Notebooks/dataset/bike/'\n",
    "aeroplane_dir = '/content/drive/MyDrive/Colab Notebooks/dataset/aeroplane/'\n",
    "\n",
    "def count_images(directory):\n",
    "    return len([file for file in os.listdir(directory) if file.endswith(('.jpg', '.jpeg', '.png', '.bmp'))])\n",
    "\n",
    "# Get the counts for each directory\n",
    "car_count = count_images(car_dir)\n",
    "bike_count = count_images(bike_dir)\n",
    "aeroplane_count = count_images(aeroplane_dir)\n",
    "# Print the results\n",
    "print(f\"Number of images in 'car' directory: {car_count}\")\n",
    "print(f\"Number of images in 'bike' directory: {bike_count}\")\n",
    "print(f\"Number of images in 'aeroplane' directory: {aeroplane_count}\")\n",
    "\n",
    "train_dir = '/content/drive/MyDrive/Colab Notebooks/dataset/'\n",
    "image_size = (224, 224)\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # Split data into training and validation sets\n",
    ")\n",
    "\n",
    "# Load and preprocess the data\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(3, activation='softmax')(x)  # Change to 7 classes to match the data\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_data\n",
    ")\n",
    "\n",
    "\n",
    "val_loss, val_accuracy = model.evaluate(validation_data)\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "for layer in base_model.layers[-4:]:  # Use 'base_model' instead of 'vgg16_base'\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_fine_tune = model.fit(\n",
    "    train_data,\n",
    "    steps_per_epoch=train_data.samples // batch_size,\n",
    "    validation_data=validation_data,\n",
    "    validation_steps=validation_data.samples // batch_size,\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "model.save('/content/drive/MyDrive/Colab Notebooks/fine_tuned_vgg16.h5')\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23273,
     "status": "ok",
     "timestamp": 1737903792981,
     "user": {
      "displayName": "Jithin S John",
      "userId": "11096614169170253604"
     },
     "user_tz": -330
    },
    "id": "c8c1FJZfIOj1",
    "outputId": "b4fe1eca-ab9e-4528-c9f4-370472f71953"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 412,
     "status": "ok",
     "timestamp": 1737903793380,
     "user": {
      "displayName": "Jithin S John",
      "userId": "11096614169170253604"
     },
     "user_tz": -330
    },
    "id": "HibXIZXnISF9",
    "outputId": "00475dad-7954-49e4-aff6-4cf14f3d3bcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in 'car' directory: 40\n",
      "Number of images in 'bike' directory: 40\n",
      "Number of images in 'aeroplane' directory: 40\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the paths to the subdirectories\n",
    "\n",
    "car_dir = '/content/drive/MyDrive/Colab Notebooks/dataset/car/'\n",
    "bike_dir = '/content/drive/MyDrive/Colab Notebooks/dataset/bike/'\n",
    "aeroplane_dir = '/content/drive/MyDrive/Colab Notebooks/dataset/aeroplane/'\n",
    "\n",
    "def count_images(directory):\n",
    "    return len([file for file in os.listdir(directory) if file.endswith(('.jpg', '.jpeg', '.png', '.bmp'))])\n",
    "\n",
    "# Get the counts for each directory\n",
    "car_count = count_images(car_dir)\n",
    "bike_count = count_images(bike_dir)\n",
    "aeroplane_count = count_images(aeroplane_dir)\n",
    "# Print the results\n",
    "print(f\"Number of images in 'car' directory: {car_count}\")\n",
    "print(f\"Number of images in 'bike' directory: {bike_count}\")\n",
    "print(f\"Number of images in 'aeroplane' directory: {aeroplane_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 386,
     "status": "ok",
     "timestamp": 1737903835013,
     "user": {
      "displayName": "Jithin S John",
      "userId": "11096614169170253604"
     },
     "user_tz": -330
    },
    "id": "MVsIsDxzIwXI"
   },
   "outputs": [],
   "source": [
    "train_dir = '/content/drive/MyDrive/Colab Notebooks/dataset/'\n",
    "image_size = (224, 224)\n",
    "batch_size = 32\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 407,
     "status": "ok",
     "timestamp": 1737903838626,
     "user": {
      "displayName": "Jithin S John",
      "userId": "11096614169170253604"
     },
     "user_tz": -330
    },
    "id": "jBmcblqOI8sq",
    "outputId": "5d98b9d8-b148-41a9-ccc3-9fca9b243b0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 96 images belonging to 3 classes.\n",
      "Found 24 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # Split data into training and validation sets\n",
    ")\n",
    "\n",
    "# Load and preprocess the data\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mWKfzxSaJG7h",
    "outputId": "c94ed8d7-cd73-45d1-e7f8-b901e555df1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 34s/step - accuracy: 0.5521 - loss: 1.1296 - val_accuracy: 0.8333 - val_loss: 0.4517\n",
      "Epoch 2/10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(3, activation='softmax')(x)  # Change to 7 classes to match the data\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JTECHwHdJbXj"
   },
   "outputs": [],
   "source": [
    "val_loss, val_accuracy = model.evaluate(validation_data)\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74kkbNuoJjtH"
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers[-4:]:  # Use 'base_model' instead of 'vgg16_base'\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_fine_tune = model.fit(\n",
    "    train_data,\n",
    "    steps_per_epoch=train_data.samples // batch_size,\n",
    "    validation_data=validation_data,\n",
    "    validation_steps=validation_data.samples // batch_size,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kQzApPGUJqfe"
   },
   "outputs": [],
   "source": [
    "model.save('/content/drive/MyDrive/Colab Notebooks/fine_tuned_vgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iA4VVX5iJwep"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMwZIDedXZ/RlYxWYcUnKit",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
